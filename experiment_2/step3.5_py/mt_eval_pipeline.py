# -*- coding: utf-8 -*-
"""mt_eval_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jwMeyUoOtG7xSAf0WGzAt-8_vorNhCLJ
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Machine Translation Pipeline Processor

This script processes machine translation outputs through a 4-step pipeline:
1. Analyze .wmt.seg.score file to extract system names and line counts
2. Merge translation outputs from multiple systems
3. Align with source JSONL file
4. Rebuild .wmt.seg.score format using semantic similarity scores

Each step can be run independently using command line arguments.

Author: Claude
Date: May 5, 2025
"""

import os
import json
import sys
import argparse
from collections import OrderedDict
from typing import List, Dict, Tuple, Any


def analyze_wmt_seg_score(filename: str, output_file: str = None) -> Tuple[List[str], Dict[str, int], int]:
    """
    Step 1: Analyze .wmt.seg.score file

    Args:
        filename: Path to the .wmt.seg.score file
        output_file: Optional path to save system names to a file

    Returns:
        Tuple of (ordered system names, system line counts, total lines)
    """
    if not os.path.exists(filename):
        raise FileNotFoundError(f"Score file not found: {filename}")

    system_names = []
    system_counts = OrderedDict()
    total_lines = 0

    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                # Extract the first column (system name)
                parts = line.split('\t')
                if not parts:
                    continue

                system_name = parts[0]

                # Record system names in order of first appearance
                if system_name not in system_counts:
                    system_names.append(system_name)
                    system_counts[system_name] = 1
                else:
                    system_counts[system_name] += 1

                total_lines += 1
    except Exception as e:
        print(f"Error analyzing score file: {e}")
        sys.exit(1)

    # Print results
    print("\n=== Step 1: Analysis of .wmt.seg.score file ===")
    print(f"Total number of lines: {total_lines}")
    print("\nOrdered list of system names:")
    for idx, name in enumerate(system_names, 1):
        print(f"{idx}. {name}")

    print("\nSystem line counts:")
    print("-" * 40)
    print(f"{'System Name':<25} | {'Count':>10}")
    print("-" * 40)
    for name, count in system_counts.items():
        print(f"{name:<25} | {count:>10}")
    print("-" * 40)

    # Save system names to file if output_file is provided
    if output_file:
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                # Save system names and their counts
                f.write(json.dumps({
                    "system_names": system_names,
                    "system_counts": {k: v for k, v in system_counts.items()},
                    "total_lines": total_lines
                }, ensure_ascii=False, indent=2))
            print(f"System information saved to {output_file}")
        except Exception as e:
            print(f"Error saving system information: {e}")

    return system_names, system_counts, total_lines


def merge_translation_outputs(system_names_file: str, output_file: str = None) -> List[str]:
    """
    Step 2: Merge translation outputs from multiple systems

    Args:
        system_names_file: Path to JSON file with system names (from Step 1)
        output_file: Optional path to save merged translations

    Returns:
        List of merged translations in system-order blocks
    """
    # Load system names from file
    if not os.path.exists(system_names_file):
        raise FileNotFoundError(f"System names file not found: {system_names_file}")

    try:
        with open(system_names_file, 'r', encoding='utf-8') as f:
            system_info = json.load(f)
            system_names = system_info["system_names"]
    except Exception as e:
        print(f"Error loading system names: {e}")
        sys.exit(1)

    all_translations = []
    system_line_counts = {}

    print("\n=== Step 2: Merging translation outputs ===")

    for system_name in system_names:
        system_file = f"{system_name}.txt"

        if not os.path.exists(system_file):
            raise FileNotFoundError(f"Translation file not found: {system_file}")

        try:
            with open(system_file, 'r', encoding='utf-8') as f:
                lines = [line.strip() for line in f.readlines()]
                system_line_counts[system_name] = len(lines)
                all_translations.extend(lines)
                print(f"Loaded {len(lines)} translations from {system_file}")
        except Exception as e:
            print(f"Error reading translation file {system_file}: {e}")
            sys.exit(1)

    # Verify all systems have the same number of translations
    if len(set(system_line_counts.values())) > 1:
        print("WARNING: Not all system files have the same number of translations!")
        for name, count in system_line_counts.items():
            print(f"  {name}: {count} lines")

    total_merged = len(all_translations)
    print(f"\nTotal merged translations: {total_merged}")

    # Save merged translations if output_file is provided
    if output_file:
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for translation in all_translations:
                    f.write(translation + '\n')
            print(f"Merged translations saved to {output_file}")
        except Exception as e:
            print(f"Error saving merged translations: {e}")

    return all_translations


def align_with_source(system_names_file: str, merged_translations_file: str,
                     source_file: str, output_file: str) -> None:
    """
    Step 3: Align with source JSONL file

    Args:
        system_names_file: Path to JSON file with system names (from Step 1)
        merged_translations_file: Path to file with merged translations (from Step 2)
        source_file: Path to source JSONL file
        output_file: Path to output aligned JSONL file
    """
    if not os.path.exists(system_names_file):
        raise FileNotFoundError(f"System names file not found: {system_names_file}")

    if not os.path.exists(merged_translations_file):
        raise FileNotFoundError(f"Merged translations file not found: {merged_translations_file}")

    if not os.path.exists(source_file):
        raise FileNotFoundError(f"Source file not found: {source_file}")

    # Load system names
    try:
        with open(system_names_file, 'r', encoding='utf-8') as f:
            system_info = json.load(f)
            system_names = system_info["system_names"]
    except Exception as e:
        print(f"Error loading system names: {e}")
        sys.exit(1)

    # Load merged translations
    merged_translations = []
    try:
        with open(merged_translations_file, 'r', encoding='utf-8') as f:
            merged_translations = [line.strip() for line in f.readlines()]
    except Exception as e:
        print(f"Error loading merged translations: {e}")
        sys.exit(1)

    print("\n=== Step 3: Aligning with source JSONL ===")

    # Load source JSONL
    source_data = []
    try:
        with open(source_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    source_data.append(json.loads(line))
    except Exception as e:
        print(f"Error reading source file: {e}")
        sys.exit(1)

    source_count = len(source_data)
    system_count = len(system_names)
    expected_translations = source_count * system_count

    print(f"Source sentences: {source_count}")
    print(f"Translation systems: {system_count}")
    print(f"Expected translations: {expected_translations}")
    print(f"Actual translations: {len(merged_translations)}")

    if expected_translations != len(merged_translations):
        print(f"ERROR: Translation count mismatch! Expected {expected_translations}, got {len(merged_translations)}")
        sys.exit(1)

    # Create aligned data ordered by system rather than by source sentence
    aligned_data = []

    # For each system, process all its translations in order
    for system_idx, system_name in enumerate(system_names):
        system_start_idx = system_idx * source_count

        for src_idx, src_item in enumerate(source_data):
            # Calculate the index in merged_translations for this system and source
            translation_idx = system_start_idx + src_idx

            if translation_idx >= len(merged_translations):
                print(f"ERROR: Translation index {translation_idx} out of bounds")
                sys.exit(1)

            translation = merged_translations[translation_idx]

            # Create aligned entry
            aligned_entry = {
                "src": src_item["src"],
                "src_translation": src_item["src_translation"],
                "mt": translation,
                "system_name": system_name
            }

            aligned_data.append(aligned_entry)

    # Write aligned data to output file
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            for entry in aligned_data:
                f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    except Exception as e:
        print(f"Error writing aligned data: {e}")
        sys.exit(1)

    print(f"Successfully aligned data and wrote {len(aligned_data)} entries to {output_file}")


def rebuild_wmt_format(enhanced_jsonl: str, original_score_file: str, output_score_file: str) -> None:
    """
    Step 4: Rebuild .wmt.seg.score format using semantic similarity

    Args:
        enhanced_jsonl: Path to enhanced JSONL with semantic similarity scores
        original_score_file: Path to original .wmt.seg.score file
        output_score_file: Path to output .wmt.seg.score file
    """
    if not os.path.exists(enhanced_jsonl):
        raise FileNotFoundError(f"Enhanced JSONL file not found: {enhanced_jsonl}")

    if not os.path.exists(original_score_file):
        raise FileNotFoundError(f"Original score file not found: {original_score_file}")

    print("\n=== Step 4: Rebuilding .wmt.seg.score format ===")

    # Load enhanced JSONL
    enhanced_data = []
    try:
        with open(enhanced_jsonl, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    entry = json.loads(line)
                    if "semantic_similarity" not in entry:
                        print(f"WARNING: Missing 'semantic_similarity' field in entry: {entry}")
                        continue
                    enhanced_data.append(entry)
    except Exception as e:
        print(f"Error reading enhanced JSONL: {e}")
        sys.exit(1)

    # Read original score file to maintain exact order
    original_lines = []
    try:
        with open(original_score_file, 'r', encoding='utf-8') as f:
            original_lines = [line.strip() for line in f if line.strip()]
    except Exception as e:
        print(f"Error reading original score file: {e}")
        sys.exit(1)

    # Create mapping from (system_name, index) to semantic_similarity
    system_scores = {}
    system_counts = {}

    for entry in enhanced_data:
        system_name = entry["system_name"]
        if system_name not in system_counts:
            system_counts[system_name] = 0

        idx = system_counts[system_name]
        system_scores[(system_name, idx)] = entry["semantic_similarity"]
        system_counts[system_name] += 1

    # Generate new score file with same order but updated scores
    new_lines = []
    processed_counts = {system: 0 for system in system_counts.keys()}

    for line in original_lines:
        parts = line.split('\t')
        if not parts:
            continue

        system_name = parts[0]
        idx = processed_counts.get(system_name, 0)

        if (system_name, idx) not in system_scores:
            print(f"WARNING: Missing score for system {system_name}, index {idx}")
            new_score = 0.0  # Default fallback
        else:
            new_score = system_scores[(system_name, idx)]

        new_lines.append(f"{system_name}\t{new_score}")
        processed_counts[system_name] = idx + 1

    # Write new score file
    try:
        with open(output_score_file, 'w', encoding='utf-8') as f:
            for line in new_lines:
                f.write(line + '\n')
    except Exception as e:
        print(f"Error writing new score file: {e}")
        sys.exit(1)

    print(f"Successfully rebuilt score file with {len(new_lines)} lines")
    print(f"Original score file had {len(original_lines)} lines")


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Machine Translation Pipeline Processor")

    # Add global argument for step selection
    parser.add_argument("--step", type=int, choices=[1, 2, 3, 4],
                        help="Select which step to run (1-4)")

    # Step 1 arguments
    parser.add_argument("--score-file", type=str,
                        help="Path to input .wmt.seg.score file (for Step 1)")
    parser.add_argument("--sys-info-output", type=str,
                        help="Path to output system information JSON file (for Step 1)")

    # Step 2 arguments
    parser.add_argument("--sys-info", type=str,
                        help="Path to system information JSON file (for Step 2)")
    parser.add_argument("--merged-output", type=str,
                        help="Path to output merged translations file (for Step 2)")

    # Step 3 arguments
    parser.add_argument("--merged-trans", type=str,
                        help="Path to merged translations file (for Step 3)")
    parser.add_argument("--source-jsonl", type=str,
                        help="Path to source JSONL file (for Step 3)")
    parser.add_argument("--aligned-output", type=str,
                        help="Path to output aligned JSONL file (for Step 3)")

    # Step 4 arguments
    parser.add_argument("--enhanced-jsonl", type=str,
                        help="Path to enhanced JSONL file with semantic_similarity (for Step 4)")
    parser.add_argument("--original-score", type=str,
                        help="Path to original .wmt.seg.score file (for Step 4)")
    parser.add_argument("--new-score-output", type=str,
                        help="Path to output .wmt.seg.score file (for Step 4)")

    return parser.parse_args()


def main():
    """Main function to run the pipeline"""
    args = parse_arguments()

    # If no step is specified, show help
    if args.step is None:
        print("Please specify which step to run with --step (1-4)")
        print("Example: python script.py --step 1 --score-file input.wmt.seg.score --sys-info-output system_info.json")
        print("For more information, use --help")
        sys.exit(1)

    try:
        # Step 1: Analyze .wmt.seg.score file
        if args.step == 1:
            if not args.score_file:
                print("Error: Missing required argument --score-file for Step 1")
                sys.exit(1)

            analyze_wmt_seg_score(args.score_file, args.sys_info_output)

        # Step 2: Merge translation outputs
        elif args.step == 2:
            if not args.sys_info:
                print("Error: Missing required argument --sys-info for Step 2")
                sys.exit(1)

            merge_translation_outputs(args.sys_info, args.merged_output)

        # Step 3: Align with source JSONL file
        elif args.step == 3:
            if not args.sys_info or not args.merged_trans or not args.source_jsonl or not args.aligned_output:
                print("Error: Missing required arguments for Step 3")
                print("Required: --sys-info, --merged-trans, --source-jsonl, --aligned-output")
                sys.exit(1)

            align_with_source(args.sys_info, args.merged_trans, args.source_jsonl, args.aligned_output)

        # Step 4: Rebuild .wmt.seg.score format using semantic similarity
        elif args.step == 4:
            if not args.enhanced_jsonl or not args.original_score or not args.new_score_output:
                print("Error: Missing required arguments for Step 4")
                print("Required: --enhanced-jsonl, --original-score, --new-score-output")
                sys.exit(1)

            rebuild_wmt_format(args.enhanced_jsonl, args.original_score, args.new_score_output)

        print(f"\n=== Step {args.step} completed successfully! ===")

    except Exception as e:
        print(f"Error in Step {args.step}: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()